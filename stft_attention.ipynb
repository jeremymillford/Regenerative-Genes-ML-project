{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Gene Sequence Regenerative Contributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Jaeyoon Jung, Jeremy Milford, Shree Patel, Cynthia Perez\n",
    "\n",
    "This notebook develops a model from one hot encoded gene sequences of the axolotl, norwegian rat, and zebrafish. This notebook uses one hot encoded and Fourier transformed data to build a CNN with an attention component. The model is further optimized with GridSearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 02:48:19.138795: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping long sequence of length 16\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Reshape, Conv1D, Layer, MaxPooling1D, MultiHeadAttention, Flatten, Input, concatenate, Attention, Flatten, TimeDistributed, BatchNormalization, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from onehot import onehote\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import torch\n",
    "from RNA_tokenizer import extract_rna_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(2)  \n",
    "# tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_name</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>gc_content</th>\n",
       "      <th>at_gc_ratio</th>\n",
       "      <th>kmer_3_GGG</th>\n",
       "      <th>kmer_3_GGC</th>\n",
       "      <th>kmer_3_GCG</th>\n",
       "      <th>kmer_3_CGG</th>\n",
       "      <th>kmer_3_GCT</th>\n",
       "      <th>kmer_3_CTG</th>\n",
       "      <th>...</th>\n",
       "      <th>kmer_3_TAG</th>\n",
       "      <th>kmer_3_CAN</th>\n",
       "      <th>kmer_3_ANN</th>\n",
       "      <th>kmer_3_NNN</th>\n",
       "      <th>kmer_3_NNT</th>\n",
       "      <th>kmer_3_NTA</th>\n",
       "      <th>organism</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>regen</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIPOQ</td>\n",
       "      <td>1487</td>\n",
       "      <td>0.465367</td>\n",
       "      <td>1.148844</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.022896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CTCAGGAGACCTGGCGATTTTCTCTTCATTCCTGTCTGTACGAGTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGTR1A</td>\n",
       "      <td>2286</td>\n",
       "      <td>0.463255</td>\n",
       "      <td>1.158640</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.029335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CCGAGCCTGAGGGTTGGAACCTGCAGAGCAGCGACGCCCCCTAGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGTR2</td>\n",
       "      <td>2861</td>\n",
       "      <td>0.386928</td>\n",
       "      <td>1.584463</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>0.010843</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CCAGAGTCTGGGGATGGAGCGAGCACAGAATTGAAAGCTTTCTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMTN</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>0.013592</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.025243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>X2</td>\n",
       "      <td>1</td>\n",
       "      <td>AAAAGATAAATTTTGCACCAGAGTAAAGTGGAGAAGTCATCTGGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARHGDIA</td>\n",
       "      <td>89866</td>\n",
       "      <td>0.470211</td>\n",
       "      <td>1.126704</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.021421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ambystoma mexicanum</td>\n",
       "      <td>3q</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTCTAGAGCTCTCTTGTGGGACGGGAACTAGATAGACCGGAACTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  gene_name  sequence_length  gc_content  at_gc_ratio  kmer_3_GGG  kmer_3_GGC  \\\n",
       "0    ADIPOQ             1487    0.465367     1.148844    0.014141    0.016162   \n",
       "1    AGTR1A             2286    0.463255     1.158640    0.007881    0.018827   \n",
       "2     AGTR2             2861    0.386928     1.584463    0.008395    0.010843   \n",
       "3      AMTN             1032    0.465116     1.150000    0.011650    0.013592   \n",
       "4   ARHGDIA            89866    0.470211     1.126704    0.016681    0.013810   \n",
       "\n",
       "   kmer_3_GCG  kmer_3_CGG  kmer_3_GCT  kmer_3_CTG  ...  kmer_3_TAG  \\\n",
       "0    0.005387    0.005387    0.013468    0.022896  ...    0.008754   \n",
       "1    0.005692    0.004378    0.022329    0.029335  ...    0.007881   \n",
       "2    0.001399    0.001749    0.015390    0.023435  ...    0.011193   \n",
       "3    0.001942    0.001942    0.014563    0.025243  ...    0.005825   \n",
       "4    0.006310    0.007344    0.015112    0.021421  ...    0.011440   \n",
       "\n",
       "   kmer_3_CAN  kmer_3_ANN  kmer_3_NNN  kmer_3_NNT  kmer_3_NTA  \\\n",
       "0         0.0         0.0         0.0         0.0         0.0   \n",
       "1         0.0         0.0         0.0         0.0         0.0   \n",
       "2         0.0         0.0         0.0         0.0         0.0   \n",
       "3         0.0         0.0         0.0         0.0         0.0   \n",
       "4         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "              organism  chromosome  regen  \\\n",
       "0    Rattus norvegicus           2      0   \n",
       "1    Rattus norvegicus           2      0   \n",
       "2    Rattus norvegicus           2      0   \n",
       "3    Rattus norvegicus          X2      1   \n",
       "4  Ambystoma mexicanum          3q      0   \n",
       "\n",
       "                                            sequence  \n",
       "0  CTCAGGAGACCTGGCGATTTTCTCTTCATTCCTGTCTGTACGAGTG...  \n",
       "1  CCGAGCCTGAGGGTTGGAACCTGCAGAGCAGCGACGCCCCCTAGGC...  \n",
       "2  CCAGAGTCTGGGGATGGAGCGAGCACAGAATTGAAAGCTTTCTTCA...  \n",
       "3  AAAAGATAAATTTTGCACCAGAGTAAAGTGGAGAAGTCATCTGGAT...  \n",
       "4  TTTCTAGAGCTCTCTTGTGGGACGGGAACTAGATAGACCGGAACTA...  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"gene_sequences.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test, Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sequence_length', 'gc_content', 'at_gc_ratio', 'kmer_3_GGG',\n",
      "       'kmer_3_GGC', 'kmer_3_GCG', 'kmer_3_CGG', 'kmer_3_GCT', 'kmer_3_CTG',\n",
      "       'kmer_3_TGC', 'kmer_3_GCC', 'kmer_3_CCG', 'kmer_3_CGC', 'kmer_3_CCA',\n",
      "       'kmer_3_CAG', 'kmer_3_AGC', 'kmer_3_CCC', 'kmer_3_CTA', 'kmer_3_TAA',\n",
      "       'kmer_3_AAG', 'kmer_3_AGG', 'kmer_3_CTC', 'kmer_3_TCG', 'kmer_3_GGA',\n",
      "       'kmer_3_GAG', 'kmer_3_AGA', 'kmer_3_TCT', 'kmer_3_TGT', 'kmer_3_GTT',\n",
      "       'kmer_3_TTT', 'kmer_3_TTC', 'kmer_3_TCC', 'kmer_3_AGT', 'kmer_3_GTC',\n",
      "       'kmer_3_GTG', 'kmer_3_TGG', 'kmer_3_CTT', 'kmer_3_TTA', 'kmer_3_AAA',\n",
      "       'kmer_3_CAC', 'kmer_3_ACT', 'kmer_3_CGT', 'kmer_3_CAA', 'kmer_3_AAT',\n",
      "       'kmer_3_ATG', 'kmer_3_TAT', 'kmer_3_TGA', 'kmer_3_GAC', 'kmer_3_ACA',\n",
      "       'kmer_3_TCA', 'kmer_3_CCT', 'kmer_3_ACG', 'kmer_3_GAT', 'kmer_3_ATC',\n",
      "       'kmer_3_CGA', 'kmer_3_CAT', 'kmer_3_TAC', 'kmer_3_AAC', 'kmer_3_GCA',\n",
      "       'kmer_3_GAA', 'kmer_3_ACC', 'kmer_3_GGT', 'kmer_3_ATT', 'kmer_3_TTG',\n",
      "       'kmer_3_ATA', 'kmer_3_GTA', 'kmer_3_TAG', 'kmer_3_CAN', 'kmer_3_ANN',\n",
      "       'kmer_3_NNN', 'kmer_3_NNT', 'kmer_3_NTA', 'organism', 'chromosome',\n",
      "       'regen', 'sequence'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organism</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>regen</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CTCAGGAGACCTGGCGATTTTCTCTTCATTCCTGTCTGTACGAGTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CCGAGCCTGAGGGTTGGAACCTGCAGAGCAGCGACGCCCCCTAGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CCAGAGTCTGGGGATGGAGCGAGCACAGAATTGAAAGCTTTCTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rattus norvegicus</td>\n",
       "      <td>X2</td>\n",
       "      <td>1</td>\n",
       "      <td>AAAAGATAAATTTTGCACCAGAGTAAAGTGGAGAAGTCATCTGGAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ambystoma mexicanum</td>\n",
       "      <td>3q</td>\n",
       "      <td>0</td>\n",
       "      <td>TTTCTAGAGCTCTCTTGTGGGACGGGAACTAGATAGACCGGAACTA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              organism chromosome  regen  \\\n",
       "0    Rattus norvegicus          2      0   \n",
       "1    Rattus norvegicus          2      0   \n",
       "2    Rattus norvegicus          2      0   \n",
       "3    Rattus norvegicus         X2      1   \n",
       "4  Ambystoma mexicanum         3q      0   \n",
       "\n",
       "                                            sequence  \n",
       "0  CTCAGGAGACCTGGCGATTTTCTCTTCATTCCTGTCTGTACGAGTG...  \n",
       "1  CCGAGCCTGAGGGTTGGAACCTGCAGAGCAGCGACGCCCCCTAGGC...  \n",
       "2  CCAGAGTCTGGGGATGGAGCGAGCACAGAATTGAAAGCTTTCTTCA...  \n",
       "3  AAAAGATAAATTTTGCACCAGAGTAAAGTGGAGAAGTCATCTGGAT...  \n",
       "4  TTTCTAGAGCTCTCTTGTGGGACGGGAACTAGATAGACCGGAACTA...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop gene_name and separate features and target \n",
    "X = features_df.drop(columns=['gene_name'])\n",
    "y = (features_df['regen']).astype(int)  \n",
    "y = y.to_numpy()\n",
    "\n",
    "# Choose only numeric features for modeling\n",
    "X_col = X.columns\n",
    "print(X_col)\n",
    "X_numeric_features = [\"sequence_length\", \"gc_content\", \"at_gc_ratio\", 'kmer_3_GGG',\n",
    "       'kmer_3_GGC', 'kmer_3_GCG', 'kmer_3_CGG', 'kmer_3_GCT', 'kmer_3_CTG',\n",
    "       'kmer_3_TGC', 'kmer_3_GCC', 'kmer_3_CCG', 'kmer_3_CGC', 'kmer_3_CCA',\n",
    "       'kmer_3_CAG', 'kmer_3_AGC', 'kmer_3_CCC', 'kmer_3_CTA', 'kmer_3_TAA',\n",
    "       'kmer_3_AAG', 'kmer_3_AGG', 'kmer_3_CTC', 'kmer_3_TCG', 'kmer_3_GGA',\n",
    "       'kmer_3_GAG', 'kmer_3_AGA', 'kmer_3_TCT', 'kmer_3_TGT', 'kmer_3_GTT',\n",
    "       'kmer_3_TTT', 'kmer_3_TTC', 'kmer_3_TCC', 'kmer_3_AGT', 'kmer_3_GTC',\n",
    "       'kmer_3_GTG', 'kmer_3_TGG', 'kmer_3_CTT', 'kmer_3_TTA', 'kmer_3_AAA',\n",
    "       'kmer_3_CAC', 'kmer_3_ACT', 'kmer_3_CGT', 'kmer_3_CAA', 'kmer_3_AAT',\n",
    "       'kmer_3_ATG', 'kmer_3_TAT', 'kmer_3_TGA', 'kmer_3_GAC', 'kmer_3_ACA',\n",
    "       'kmer_3_TCA', 'kmer_3_CCT', 'kmer_3_ACG', 'kmer_3_GAT', 'kmer_3_ATC',\n",
    "       'kmer_3_CGA', 'kmer_3_CAT', 'kmer_3_TAC', 'kmer_3_AAC', 'kmer_3_GCA',\n",
    "       'kmer_3_GAA', 'kmer_3_ACC', 'kmer_3_GGT', 'kmer_3_ATT', 'kmer_3_TTG',\n",
    "       'kmer_3_ATA', 'kmer_3_GTA', 'kmer_3_TAG', 'kmer_3_CAN', 'kmer_3_ANN',\n",
    "       'kmer_3_NNN', 'kmer_3_NNT', 'kmer_3_NTA']\n",
    "\n",
    "X = X.drop(columns = X_numeric_features)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 34000\n",
      "Skipping long sequence of length 49812\n",
      "Skipping long sequence of length 203661\n",
      "Skipping long sequence of length 508680\n",
      "Skipping long sequence of length 227268\n",
      "Skipping long sequence of length 93966\n",
      "Skipping long sequence of length 53907\n",
      "Skipping long sequence of length 992616\n",
      "Skipping long sequence of length 188442\n",
      "Skipping long sequence of length 162117\n",
      "Skipping long sequence of length 43350\n",
      "Skipping long sequence of length 183564\n",
      "Skipping long sequence of length 498336\n",
      "Skipping long sequence of length 108543\n",
      "Skipping long sequence of length 435015\n",
      "Skipping long sequence of length 158358\n",
      "Skipping long sequence of length 105993\n",
      "Skipping long sequence of length 379899\n",
      "Skipping long sequence of length 113571\n",
      "Skipping long sequence of length 91176\n",
      "Skipping long sequence of length 182880\n",
      "Skipping long sequence of length 130887\n",
      "Skipping long sequence of length 98136\n",
      "Skipping long sequence of length 1257951\n",
      "Skipping long sequence of length 196143\n",
      "Skipping long sequence of length 148323\n",
      "Skipping long sequence of length 286872\n",
      "Skipping long sequence of length 467916\n",
      "Skipping long sequence of length 117525\n",
      "Skipping long sequence of length 375825\n",
      "Skipping long sequence of length 35169\n",
      "Skipping long sequence of length 200493\n",
      "Skipping long sequence of length 36294\n",
      "Skipping long sequence of length 76974\n",
      "Skipping long sequence of length 179853\n",
      "Skipping long sequence of length 326025\n",
      "Skipping long sequence of length 212178\n",
      "Skipping long sequence of length 201267\n",
      "Skipping long sequence of length 42951\n",
      "Skipping long sequence of length 144648\n",
      "Skipping long sequence of length 42744\n",
      "Skipping long sequence of length 281721\n",
      "Skipping long sequence of length 99657\n",
      "Skipping long sequence of length 315876\n",
      "23976\n"
     ]
    }
   ],
   "source": [
    "# one hot encode each sequence and store in a NumPy array\n",
    "# determine longest sequence\n",
    "max_len = 34000\n",
    "\n",
    "print(f\"Max sequence length: {max_len}\")\n",
    "\n",
    "max_len_tokenized = 0\n",
    "\n",
    "sequences_ohe = []\n",
    "updated_Y = [] \n",
    "for i, seq in enumerate(X['sequence']):\n",
    "    tokenized = extract_rna_sequences(seq)\n",
    "    output = onehote(tokenized, max_len)\n",
    "    if output is None:\n",
    "        continue\n",
    "    else:\n",
    "        max_len_tokenized = max(max_len_tokenized, len(tokenized))\n",
    "        sequences_ohe.append(output)\n",
    "        updated_Y.append(y[i]) \n",
    "        \n",
    "sequences_X_padded = pad_sequences(sequences_ohe, padding='post', maxlen = max_len_tokenized, dtype='float32', value=0)\n",
    "# Replace the original Y_train with the updated one\n",
    "Y = np.array(updated_Y)\n",
    "\n",
    "print(max_len_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourier transform \n",
    "\n",
    "def apply_fourier_transform(padded_sequences):\n",
    "    \"\"\"\n",
    "    Apply Fourier Transform along the sequence length for each channel.\n",
    "    \"\"\"\n",
    "    # Perform Fourier Transform along the sequence length axis (axis=-1)\n",
    "    fft_result = tf.signal.fft(padded_sequences)  \n",
    "\n",
    "    magnitude_spectrum = tf.abs(fft_result) \n",
    "    return magnitude_spectrum\n",
    "\n",
    "spectrum = apply_fourier_transform(sequences_X_padded)\n",
    "\n",
    "num_frequencies = 50  # Retain only top 50 frequencies\n",
    "reduced_spectrum = spectrum[:, :, :num_frequencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "Class weights: {0: 2.1538461538461537, 1: 1.8666666666666667}\n",
      "11\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply MinMaxScaler along the axes\n",
    "normalized_spectrum = np.array([\n",
    "    scaler.fit_transform(sample) for sample in reduced_spectrum\n",
    "])\n",
    "\n",
    "# train, test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(normalized_spectrum, Y, test_size=0.2, random_state=46)\n",
    "print(len(X_train))\n",
    "\n",
    "# Class Weights\n",
    "class_0_count = np.sum(Y_train == 0)\n",
    "class_1_count = np.sum(Y_train == 1)\n",
    "\n",
    "class_weights = {0: (len(Y_train)) / class_0_count, 1: len(Y_train) / class_1_count}  # Inverse of class frequency\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "print(np.sum(Y_test == 0))\n",
    "print(len(Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This train, test split has considered the sequences of the genes and has no additional information on the chromosome, organism, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN with Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5249 - loss: 2.2620"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "batch = 2\n",
    "input_shape = (max_len_tokenized, 4)  \n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Block 1: Initial Convolution Layer\n",
    "x = Conv1D(filters=32, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Block 2: Deeper Convolution LAyer\n",
    "x = Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01))(input_layer)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Add Attention Layer\n",
    "query = Dense(32)(x)  # Transform `x` into query\n",
    "key = Dense(32)(x)    # Transform `x` into key\n",
    "value = Dense(32)(x)  # Transform `x` into value\n",
    "\n",
    "x = Attention()([query, value, key])\n",
    "\n",
    "# Flatten\n",
    "x = GlobalMaxPooling1D()(x)  # Try GlobalMaxPooling1D() as an alternative\n",
    "\n",
    "# Fully Connected Layers\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "# Output Layer\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Model Creation\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Define learning rate reduction callback\n",
    "lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    factor=0.5,          # Reduce learning rate by this factor\n",
    "    patience=3,          # Wait for 'patience' epochs before reducing\n",
    "    min_lr=1e-6          # Set a floor for the learning rate\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor\n",
    "    patience=5,           # Number of epochs without improvement\n",
    "    restore_best_weights=True  # Reverts to the best weights during training\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=50,                 # Maximum number of epochs\n",
    "    batch_size= batch,\n",
    "    validation_data = (X_test, Y_test),\n",
    "    class_weight = class_weights,\n",
    "    callbacks=[lr_callback, early_stopping])  # Add the EarlyStopping callback here\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Training History: OHE and Tokenized Sequences in CNN with Attention Layer\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size = 4)\n",
    "\n",
    "# Plot the predicted probabilities\n",
    "plt.hist(y_pred, bins=30)\n",
    "plt.title(\"Distribution of Predicted Probabilities\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Predicted probabilities:\", y_pred[:10])  # Check the first 10 predictions\n",
    "\n",
    "threshold = 0.4982  # Adjust if needed ! \n",
    "y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(Y_test, y_pred_binary)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Not Associated\", \"Associated\"], yticklabels=[\"Not Associated\", \"Associated\"])\n",
    "plt.title(\"Confusion Matrix: OHE and Tokenized Sequences in CNN with Attention Layer\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(Y_test, y_pred_binary, target_names=[\"Not Associated\", \"Associated\"]))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(Y_test, y_pred_binary))\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Replace `y_true` and `y_pred_prob` with your actual data\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement GridSearch to Optimize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CustomKerasModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, filters_1=32, filters_2=16, kernel_size=3, dropout_rate=0.3, epochs=20, batch_size=8):\n",
    "        self.filters_1 = filters_1\n",
    "        self.filters_2 = filters_2\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def build_model(self):\n",
    "        input_shape = (max_len, 4)\n",
    "        input_layer = Input(shape=input_shape)\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        x = Conv1D(filters=self.filters_1, kernel_size=self.kernel_size, kernel_regularizer=l2(0.01), activation='relu')(input_layer)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        x = Conv1D(filters=self.filters_2, kernel_size=self.kernel_size, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # Attention layer\n",
    "        query = Dense(32)(x)\n",
    "        value = Dense(32)(x)\n",
    "        key = Dense(32)(x)\n",
    "        x = Attention()([query, value, key])\n",
    "\n",
    "        # Flattening\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "        x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "        output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "        # Model creation\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_model()\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.model.evaluate(X, y, verbose=0)[1]  # return accuracy\n",
    "\n",
    "# Use the custom model for grid search\n",
    "model = CustomKerasModel()\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'batch_size': [4, 8],\n",
    "    'filters_1': [32, 16], \n",
    "    'filters_2': [32, 16],\n",
    "    'dropout_rate': [0.3, 0.4],\n",
    "    'kernel_size': [3, 5],\n",
    "    'epochs': [10, 20, 30]\n",
    "}\n",
    "\n",
    "# GridSearchCV with 3-fold cross-validation\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', verbose=1, cv=3)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_model = grid_result.best_params_\n",
    "# Create the model using the best parameters\n",
    "model = model.build_model(filters_1 = best_model['filters_1'], filters_2 = best_model['filters_2'], \n",
    "        dropout_rate = best_model['dropout_rate'], kernel_size = best_model['kernel_size']) \n",
    "\n",
    "# Fit the model and get the history\n",
    "history = model.fit(X_train, Y_train, epochs=best_model['epochs'], batch_size=best_model['batch_size'], validation_split=0.2)\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Training History: STFT CNN/Attention w MaxLen 25000 GridSearch\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = (y_pred >= 0.5).astype(int)\n",
    "\n",
    "cm = confusion_matrix(Y_test, y_pred_binary)\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Not Associated\", \"Associated\"], yticklabels=[\"Not Associated\", \"Associated\"])\n",
    "plt.title(\"Confusion Matrix: STFT CNN/Attention w MaxLen 25000 GridSearch\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(Y_test, y_pred_binary, target_names=[\"Not Associated\", \"Associated\"]))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(Y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
